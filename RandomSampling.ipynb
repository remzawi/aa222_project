{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook for testing the random sampling optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download cifar dataset if not present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already loaded.\n"
     ]
    }
   ],
   "source": [
    "from LoadCIFAR import loadCIFAR\n",
    "loadCIFAR()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Util functions to save and load objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from optimizers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.91267295e-02 6.90000000e+01 1.73000000e+02 7.38543328e-02\n",
      "  1.08276655e-02]\n",
      " [1.71855137e-05 1.90000000e+01 8.00000000e+01 9.88613923e-01\n",
      "  2.34883878e-03]\n",
      " [1.15210294e-06 5.20000000e+01 7.50000000e+01 3.84157657e-02\n",
      "  9.23096433e-04]\n",
      " [1.84919135e-05 2.10000000e+01 1.27000000e+02 8.63301710e-01\n",
      "  3.53219061e-10]\n",
      " [3.87437918e-02 3.70000000e+01 1.55000000e+02 3.58534441e-01\n",
      "  4.59667863e-07]]\n"
     ]
    }
   ],
   "source": [
    "params={'learning_rate':(1e-6,1e-1,2),\n",
    "        'batch_size':(16,256,1),\n",
    "        'nepochs':(5,5,1),\n",
    "        'conv_size1':(64,64,1),\n",
    "        'conv_size2':(64,64,1),\n",
    "        'fc_size':(50,200,1),\n",
    "        'dropout_param':(0,1,0),\n",
    "        'l2_reg':(1e-10,1,2)}\n",
    "samples=randomSearch(5,test_sampling=True,params=params)\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test random search on one sample and reduced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on sample 1\n",
      "WARNING:tensorflow:Large dropout rate: 0.694997 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train on 9500 samples, validate on 500 samples\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:Large dropout rate: 0.694997 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.694997 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "9500/9500 - 5s - loss: 3.5905 - sparse_categorical_accuracy: 0.0982 - val_loss: 2.2902 - val_sparse_categorical_accuracy: 0.1260\n",
      "Epoch 2/5\n",
      "9500/9500 - 1s - loss: 3.1492 - sparse_categorical_accuracy: 0.1196 - val_loss: 2.2627 - val_sparse_categorical_accuracy: 0.1660\n",
      "Epoch 3/5\n",
      "9500/9500 - 1s - loss: 2.9720 - sparse_categorical_accuracy: 0.1339 - val_loss: 2.2312 - val_sparse_categorical_accuracy: 0.1900\n",
      "Epoch 4/5\n",
      "9500/9500 - 1s - loss: 2.8210 - sparse_categorical_accuracy: 0.1422 - val_loss: 2.2004 - val_sparse_categorical_accuracy: 0.2300\n",
      "Epoch 5/5\n",
      "9500/9500 - 1s - loss: 2.7127 - sparse_categorical_accuracy: 0.1521 - val_loss: 2.1708 - val_sparse_categorical_accuracy: 0.2540\n"
     ]
    }
   ],
   "source": [
    "params={'learning_rate':(1e-6,1e-1,2),\n",
    "        'batch_size':(16,256,1),\n",
    "        'nepochs':(5,5,1),\n",
    "        'conv_size1':(64,64,1),\n",
    "        'conv_size2':(64,64,1),\n",
    "        'fc_size':(50,200,1),\n",
    "        'dropout_param':(0,1,0),\n",
    "        'l2_reg':(1e-10,1,2)}\n",
    "model=randomSearch(1,params=params,num_training=9500,num_val=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test random search on 5 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on sample 1\n",
      "Train on 9500 samples, validate on 500 samples\n",
      "Epoch 1/5\n",
      "9500/9500 - 3s - loss: 2.1247 - sparse_categorical_accuracy: 0.2472 - val_loss: 2.0531 - val_sparse_categorical_accuracy: 0.2360\n",
      "Epoch 2/5\n",
      "9500/9500 - 2s - loss: 1.8224 - sparse_categorical_accuracy: 0.3343 - val_loss: 1.8900 - val_sparse_categorical_accuracy: 0.2960\n",
      "Epoch 3/5\n",
      "9500/9500 - 2s - loss: 1.6566 - sparse_categorical_accuracy: 0.3806 - val_loss: 1.6067 - val_sparse_categorical_accuracy: 0.3460\n",
      "Epoch 4/5\n",
      "9500/9500 - 2s - loss: 1.5375 - sparse_categorical_accuracy: 0.4243 - val_loss: 1.5312 - val_sparse_categorical_accuracy: 0.4440\n",
      "Epoch 5/5\n",
      "9500/9500 - 2s - loss: 1.4475 - sparse_categorical_accuracy: 0.4682 - val_loss: 1.5118 - val_sparse_categorical_accuracy: 0.4400\n",
      "Starting training on sample 2\n",
      "Train on 9500 samples, validate on 500 samples\n",
      "Epoch 1/5\n",
      "9500/9500 - 3s - loss: 34.4663 - sparse_categorical_accuracy: 0.1269 - val_loss: 33.8512 - val_sparse_categorical_accuracy: 0.1960\n",
      "Epoch 2/5\n",
      "9500/9500 - 1s - loss: 33.9076 - sparse_categorical_accuracy: 0.1723 - val_loss: 33.5573 - val_sparse_categorical_accuracy: 0.2500\n",
      "Epoch 3/5\n",
      "9500/9500 - 1s - loss: 33.5242 - sparse_categorical_accuracy: 0.2100 - val_loss: 33.2516 - val_sparse_categorical_accuracy: 0.2920\n",
      "Epoch 4/5\n",
      "9500/9500 - 1s - loss: 33.1658 - sparse_categorical_accuracy: 0.2296 - val_loss: 32.9359 - val_sparse_categorical_accuracy: 0.3040\n",
      "Epoch 5/5\n",
      "9500/9500 - 1s - loss: 32.8261 - sparse_categorical_accuracy: 0.2508 - val_loss: 32.6133 - val_sparse_categorical_accuracy: 0.3020\n",
      "Starting training on sample 3\n",
      "Train on 9500 samples, validate on 500 samples\n",
      "Epoch 1/5\n",
      "9500/9500 - 3s - loss: 1.9585 - sparse_categorical_accuracy: 0.3391 - val_loss: 1.9977 - val_sparse_categorical_accuracy: 0.2840\n",
      "Epoch 2/5\n",
      "9500/9500 - 2s - loss: 1.4935 - sparse_categorical_accuracy: 0.4928 - val_loss: 1.4220 - val_sparse_categorical_accuracy: 0.5380\n",
      "Epoch 3/5\n",
      "9500/9500 - 2s - loss: 1.2719 - sparse_categorical_accuracy: 0.5715 - val_loss: 1.3478 - val_sparse_categorical_accuracy: 0.5580\n",
      "Epoch 4/5\n",
      "9500/9500 - 2s - loss: 1.1070 - sparse_categorical_accuracy: 0.6312 - val_loss: 1.2757 - val_sparse_categorical_accuracy: 0.5680\n",
      "Epoch 5/5\n",
      "9500/9500 - 2s - loss: 0.9486 - sparse_categorical_accuracy: 0.6837 - val_loss: 1.2725 - val_sparse_categorical_accuracy: 0.5780\n",
      "Starting training on sample 4\n",
      "Train on 9500 samples, validate on 500 samples\n",
      "Epoch 1/5\n",
      "9500/9500 - 2s - loss: 23.9476 - sparse_categorical_accuracy: 0.1060 - val_loss: 2.3628 - val_sparse_categorical_accuracy: 0.1260\n",
      "Epoch 2/5\n",
      "9500/9500 - 2s - loss: 2.3274 - sparse_categorical_accuracy: 0.1056 - val_loss: 2.3262 - val_sparse_categorical_accuracy: 0.0980\n",
      "Epoch 3/5\n",
      "9500/9500 - 2s - loss: 2.3255 - sparse_categorical_accuracy: 0.0960 - val_loss: 2.3237 - val_sparse_categorical_accuracy: 0.0780\n",
      "Epoch 4/5\n",
      "9500/9500 - 2s - loss: 2.3253 - sparse_categorical_accuracy: 0.1018 - val_loss: 2.3248 - val_sparse_categorical_accuracy: 0.1020\n",
      "Epoch 5/5\n",
      "9500/9500 - 2s - loss: 2.3276 - sparse_categorical_accuracy: 0.1012 - val_loss: 2.3519 - val_sparse_categorical_accuracy: 0.0820\n",
      "Starting training on sample 5\n",
      "WARNING:tensorflow:Large dropout rate: 0.694303 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train on 9500 samples, validate on 500 samples\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:Large dropout rate: 0.694303 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "9500/9500 - 3s - loss: 45.5195 - sparse_categorical_accuracy: 0.1634 - val_loss: 3.2482 - val_sparse_categorical_accuracy: 0.1700\n",
      "Epoch 2/5\n",
      "9500/9500 - 2s - loss: 2.7637 - sparse_categorical_accuracy: 0.1886 - val_loss: 2.8210 - val_sparse_categorical_accuracy: 0.1900\n",
      "Epoch 3/5\n",
      "9500/9500 - 2s - loss: 2.4778 - sparse_categorical_accuracy: 0.2027 - val_loss: 2.5363 - val_sparse_categorical_accuracy: 0.1800\n",
      "Epoch 4/5\n",
      "9500/9500 - 2s - loss: 2.3719 - sparse_categorical_accuracy: 0.2007 - val_loss: 2.2799 - val_sparse_categorical_accuracy: 0.2180\n",
      "Epoch 5/5\n",
      "9500/9500 - 2s - loss: 2.2999 - sparse_categorical_accuracy: 0.2078 - val_loss: 2.2327 - val_sparse_categorical_accuracy: 0.2120\n"
     ]
    }
   ],
   "source": [
    "params={'learning_rate':(1e-6,1e-1,2),\n",
    "        'batch_size':(16,256,1),\n",
    "        'nepochs':(5,5,1),\n",
    "        'conv_size1':(64,64,1),\n",
    "        'conv_size2':(64,64,1),\n",
    "        'fc_size':(50,200,1),\n",
    "        'dropout_param':(0,1,0),\n",
    "        'l2_reg':(1e-10,1,2)}\n",
    "best_model,best_params,best_score=randomSearch(5,params=params,num_training=9500,num_val=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 116us/sample - loss: 79.5227 - sparse_categorical_accuracy: 0.3486\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[79.52266573486328, 0.3486]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test=np.load('X_test_cifar10.npy')\n",
    "y_test=np.load('y_test_cifar10.npy')\n",
    "best_model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on n samples on full dataset and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on sample 1\n",
      "WARNING:tensorflow:Large dropout rate: 0.602547 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.602547 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.602547 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Starting training on sample 2\n",
      "WARNING:tensorflow:Large dropout rate: 0.746325 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.746325 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Starting training on sample 3\n",
      "Starting training on sample 4\n",
      "Starting training on sample 5\n",
      "Starting training on sample 6\n",
      "Starting training on sample 7\n",
      "Starting training on sample 8\n",
      "Starting training on sample 9\n",
      "Starting training on sample 10\n",
      "Starting training on sample 11\n",
      "Starting training on sample 12\n",
      "Starting training on sample 13\n",
      "Starting training on sample 14\n",
      "Starting training on sample 15\n",
      "Starting training on sample 16\n",
      "Starting training on sample 17\n",
      "Starting training on sample 18\n",
      "Starting training on sample 19\n",
      "Starting training on sample 20\n",
      "Starting training on sample 21\n",
      "Starting training on sample 22\n",
      "Starting training on sample 23\n",
      "Starting training on sample 24\n",
      "Starting training on sample 25\n",
      "Starting training on sample 26\n",
      "Starting training on sample 27\n",
      "Starting training on sample 28\n",
      "Starting training on sample 29\n",
      "Starting training on sample 30\n",
      "Starting training on sample 31\n",
      "Starting training on sample 32\n",
      "Starting training on sample 33\n",
      "Starting training on sample 34\n",
      "Starting training on sample 35\n",
      "Starting training on sample 36\n",
      "Starting training on sample 37\n",
      "Starting training on sample 38\n",
      "Starting training on sample 39\n",
      "Starting training on sample 40\n",
      "Starting training on sample 41\n",
      "Starting training on sample 42\n",
      "Starting training on sample 43\n",
      "Starting training on sample 44\n",
      "Starting training on sample 45\n",
      "Starting training on sample 46\n",
      "Starting training on sample 47\n",
      "Starting training on sample 48\n",
      "Starting training on sample 49\n",
      "Starting training on sample 50\n",
      "Starting training on sample 51\n",
      "Starting training on sample 52\n",
      "Starting training on sample 53\n",
      "Starting training on sample 54\n",
      "Starting training on sample 55\n",
      "Starting training on sample 56\n",
      "Starting training on sample 57\n",
      "Starting training on sample 58\n",
      "Starting training on sample 59\n",
      "Starting training on sample 60\n",
      "Starting training on sample 61\n",
      "Starting training on sample 62\n",
      "Starting training on sample 63\n",
      "Starting training on sample 64\n",
      "Starting training on sample 65\n",
      "Starting training on sample 66\n",
      "Starting training on sample 67\n",
      "Starting training on sample 68\n",
      "Starting training on sample 69\n",
      "Starting training on sample 70\n",
      "Starting training on sample 71\n",
      "Starting training on sample 72\n",
      "Starting training on sample 73\n",
      "Starting training on sample 74\n",
      "Starting training on sample 75\n",
      "Starting training on sample 76\n",
      "Starting training on sample 77\n",
      "Starting training on sample 78\n",
      "Starting training on sample 79\n",
      "Starting training on sample 80\n",
      "Starting training on sample 81\n",
      "Starting training on sample 82\n",
      "Starting training on sample 83\n",
      "Starting training on sample 84\n",
      "Starting training on sample 85\n",
      "Starting training on sample 86\n",
      "Starting training on sample 87\n",
      "Starting training on sample 88\n",
      "Starting training on sample 89\n",
      "Starting training on sample 90\n",
      "Starting training on sample 91\n",
      "Starting training on sample 92\n",
      "Starting training on sample 93\n",
      "Starting training on sample 94\n",
      "Starting training on sample 95\n",
      "Starting training on sample 96\n",
      "Starting training on sample 97\n",
      "Starting training on sample 98\n",
      "Starting training on sample 99\n",
      "Starting training on sample 100\n"
     ]
    }
   ],
   "source": [
    "n=100\n",
    "params={'learning_rate':(1e-6,1e-1,2),\n",
    "        'batch_size':(16,256,1),\n",
    "        'nepochs':(5,5,1),\n",
    "        'conv_size1':(64,64,1),\n",
    "        'conv_size2':(64,64,1),\n",
    "        'fc_size':(50,200,1),\n",
    "        'dropout_param':(0,1,0),\n",
    "        'l2_reg':(1e-10,1,2)}\n",
    "best_model,best_params,best_score=randomSearch(n,params=params,keras_verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: RandOptModel.tf/assets\n"
     ]
    }
   ],
   "source": [
    "best_model.save('RandOptModel.tf')\n",
    "save_obj(best_params,'RandOptParam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 114us/sample - loss: 122.3964 - sparse_categorical_accuracy: 0.2763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[122.39641005859374, 0.2763]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test=np.load('X_test_cifar10.npy')\n",
    "y_test=np.load('y_test_cifar10.npy')\n",
    "best_model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nepochs': 5, 'conv_size1': 64, 'conv_size2': 64, 'learning_rate': 0.00022997429119009176, 'batch_size': 66.0, 'fc_size': 99.0, 'dropout_param': 0.26995358030433614, 'l2_reg': 1.8878215948476188e-06}\n"
     ]
    }
   ],
   "source": [
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
