{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook for testing the random sampling optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download cifar dataset if not present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already loaded.\n"
     ]
    }
   ],
   "source": [
    "from LoadCIFAR import loadCIFAR\n",
    "loadCIFAR()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Util functions to save and load objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from optimizers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.97776270e-03 7.40000000e+01 1.26000000e+02 1.17000000e+02\n",
      "  1.12000000e+02 1.38000000e+02 6.47166464e-02 1.10055048e-07]\n",
      " [6.84636037e-03 6.00000000e+01 4.20000000e+01 4.70000000e+01\n",
      "  1.03000000e+02 1.30000000e+02 6.76571311e-01 2.23138555e-04]\n",
      " [1.28765611e-04 2.52000000e+02 9.20000000e+01 6.30000000e+01\n",
      "  8.80000000e+01 1.91000000e+02 7.56456088e-01 1.13722364e-07]\n",
      " [7.01492799e-04 7.40000000e+01 6.80000000e+01 1.23000000e+02\n",
      "  1.24000000e+02 1.35000000e+02 6.94298461e-01 3.87697498e-06]\n",
      " [9.44893241e-03 2.10000000e+02 3.70000000e+01 1.04000000e+02\n",
      "  8.80000000e+01 1.46000000e+02 4.08664229e-01 2.03550521e-03]]\n"
     ]
    }
   ],
   "source": [
    "params={'learning_rate':(1e-4,1e-1,2),\n",
    "        'batch_size':(32,256,1),\n",
    "        'nepochs':(8,8,1),\n",
    "        'conv_size1':(32,128,1),\n",
    "        'conv_size2':(32,128,1),\n",
    "        'conv_size3':(32,128,1),\n",
    "        'fc_size':(50,200,1),\n",
    "        'dropout_param':(0,0.8,0),\n",
    "        'l2_reg':(1e-10,1,2)}\n",
    "samples=randomSearch(5,test_sampling=True,params=params)\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test random search on one sample and reduced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on sample 1\n",
      "Train on 9500 samples, validate on 500 samples\n",
      "Epoch 1/8\n",
      "9500/9500 - 5s - loss: 2.3955 - sparse_categorical_accuracy: 0.2083 - val_loss: 2.0534 - val_sparse_categorical_accuracy: 0.2320\n",
      "Epoch 2/8\n",
      "9500/9500 - 1s - loss: 1.8427 - sparse_categorical_accuracy: 0.2901 - val_loss: 1.8140 - val_sparse_categorical_accuracy: 0.2920\n",
      "Epoch 3/8\n",
      "9500/9500 - 1s - loss: 1.6677 - sparse_categorical_accuracy: 0.3503 - val_loss: 1.5773 - val_sparse_categorical_accuracy: 0.3580\n",
      "Epoch 4/8\n",
      "9500/9500 - 1s - loss: 1.5549 - sparse_categorical_accuracy: 0.3858 - val_loss: 1.6427 - val_sparse_categorical_accuracy: 0.3900\n",
      "Epoch 5/8\n",
      "9500/9500 - 1s - loss: 1.4991 - sparse_categorical_accuracy: 0.4135 - val_loss: 1.4689 - val_sparse_categorical_accuracy: 0.4180\n",
      "Epoch 6/8\n",
      "9500/9500 - 1s - loss: 1.3951 - sparse_categorical_accuracy: 0.4581 - val_loss: 1.4582 - val_sparse_categorical_accuracy: 0.4140\n",
      "Epoch 7/8\n",
      "9500/9500 - 1s - loss: 1.3591 - sparse_categorical_accuracy: 0.4725 - val_loss: 1.3748 - val_sparse_categorical_accuracy: 0.4700\n",
      "Epoch 8/8\n",
      "9500/9500 - 1s - loss: 1.2961 - sparse_categorical_accuracy: 0.5059 - val_loss: 1.3026 - val_sparse_categorical_accuracy: 0.5180\n"
     ]
    }
   ],
   "source": [
    "params={'learning_rate':(1e-4,1e-1,2),\n",
    "        'batch_size':(32,256,1),\n",
    "        'nepochs':(8,8,1),\n",
    "        'conv_size1':(32,128,1),\n",
    "        'conv_size2':(32,128,1),\n",
    "        'conv_size3':(32,128,1),\n",
    "        'fc_size':(50,200,1),\n",
    "        'dropout_param':(0,0.8,0),\n",
    "        'l2_reg':(1e-10,1,2)}\n",
    "params,score=randomSearch(1,params=params,num_training=9500,num_val=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test random search on 5 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on sample 1\n",
      "Train on 9500 samples, validate on 500 samples\n",
      "Epoch 1/8\n",
      "9500/9500 - 3s - loss: 50.5111 - sparse_categorical_accuracy: 0.2318 - val_loss: 5.9024 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 2/8\n",
      "9500/9500 - 1s - loss: 3.9788 - sparse_categorical_accuracy: 0.3192 - val_loss: 3.6382 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 3/8\n",
      "9500/9500 - 1s - loss: 2.9981 - sparse_categorical_accuracy: 0.3235 - val_loss: 3.1862 - val_sparse_categorical_accuracy: 0.1080\n",
      "Epoch 4/8\n",
      "9500/9500 - 1s - loss: 2.6461 - sparse_categorical_accuracy: 0.3285 - val_loss: 2.9895 - val_sparse_categorical_accuracy: 0.1020\n",
      "Epoch 5/8\n",
      "9500/9500 - 1s - loss: 2.5476 - sparse_categorical_accuracy: 0.2943 - val_loss: 2.8479 - val_sparse_categorical_accuracy: 0.0980\n",
      "Epoch 6/8\n",
      "9500/9500 - 1s - loss: 2.4099 - sparse_categorical_accuracy: 0.3031 - val_loss: 2.7723 - val_sparse_categorical_accuracy: 0.1720\n",
      "Epoch 7/8\n",
      "9500/9500 - 1s - loss: 2.3750 - sparse_categorical_accuracy: 0.2942 - val_loss: 2.7038 - val_sparse_categorical_accuracy: 0.1620\n",
      "Epoch 8/8\n",
      "9500/9500 - 1s - loss: 2.3358 - sparse_categorical_accuracy: 0.2858 - val_loss: 2.6504 - val_sparse_categorical_accuracy: 0.1660\n",
      "Starting training on sample 2\n",
      "Train on 9500 samples, validate on 500 samples\n",
      "Epoch 1/8\n",
      "9500/9500 - 4s - loss: 2.0390 - sparse_categorical_accuracy: 0.2821 - val_loss: 2.1919 - val_sparse_categorical_accuracy: 0.1420\n",
      "Epoch 2/8\n",
      "9500/9500 - 2s - loss: 1.6110 - sparse_categorical_accuracy: 0.4159 - val_loss: 2.3545 - val_sparse_categorical_accuracy: 0.1740\n",
      "Epoch 3/8\n",
      "9500/9500 - 2s - loss: 1.4361 - sparse_categorical_accuracy: 0.4784 - val_loss: 2.0411 - val_sparse_categorical_accuracy: 0.2660\n",
      "Epoch 4/8\n",
      "9500/9500 - 2s - loss: 1.3449 - sparse_categorical_accuracy: 0.5163 - val_loss: 1.6956 - val_sparse_categorical_accuracy: 0.3720\n",
      "Epoch 5/8\n",
      "9500/9500 - 2s - loss: 1.2490 - sparse_categorical_accuracy: 0.5503 - val_loss: 1.3635 - val_sparse_categorical_accuracy: 0.4820\n",
      "Epoch 6/8\n",
      "9500/9500 - 2s - loss: 1.1628 - sparse_categorical_accuracy: 0.5821 - val_loss: 1.2025 - val_sparse_categorical_accuracy: 0.5520\n",
      "Epoch 7/8\n",
      "9500/9500 - 2s - loss: 1.1021 - sparse_categorical_accuracy: 0.6091 - val_loss: 1.1789 - val_sparse_categorical_accuracy: 0.5760\n",
      "Epoch 8/8\n",
      "9500/9500 - 2s - loss: 1.0429 - sparse_categorical_accuracy: 0.6223 - val_loss: 1.0847 - val_sparse_categorical_accuracy: 0.6180\n",
      "Starting training on sample 3\n",
      "Train on 9500 samples, validate on 500 samples\n",
      "Epoch 1/8\n",
      "9500/9500 - 3s - loss: 3.9054 - sparse_categorical_accuracy: 0.1062 - val_loss: 2.3028 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 2/8\n",
      "9500/9500 - 1s - loss: 2.3026 - sparse_categorical_accuracy: 0.1019 - val_loss: 2.3023 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 3/8\n",
      "9500/9500 - 1s - loss: 2.3025 - sparse_categorical_accuracy: 0.1028 - val_loss: 2.3020 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 4/8\n",
      "9500/9500 - 1s - loss: 2.3026 - sparse_categorical_accuracy: 0.1022 - val_loss: 2.3022 - val_sparse_categorical_accuracy: 0.1000\n",
      "Epoch 5/8\n",
      "9500/9500 - 1s - loss: 2.3024 - sparse_categorical_accuracy: 0.0976 - val_loss: 2.3021 - val_sparse_categorical_accuracy: 0.1000\n",
      "Epoch 6/8\n",
      "9500/9500 - 1s - loss: 2.3025 - sparse_categorical_accuracy: 0.1003 - val_loss: 2.3015 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 7/8\n",
      "9500/9500 - 1s - loss: 2.3026 - sparse_categorical_accuracy: 0.1002 - val_loss: 2.3017 - val_sparse_categorical_accuracy: 0.1100\n",
      "Epoch 8/8\n",
      "9500/9500 - 1s - loss: 2.3025 - sparse_categorical_accuracy: 0.0982 - val_loss: 2.3016 - val_sparse_categorical_accuracy: 0.1000\n",
      "Starting training on sample 4\n",
      "Train on 9500 samples, validate on 500 samples\n",
      "Epoch 1/8\n",
      "9500/9500 - 4s - loss: 16.9281 - sparse_categorical_accuracy: 0.2215 - val_loss: 2.5841 - val_sparse_categorical_accuracy: 0.1080\n",
      "Epoch 2/8\n",
      "9500/9500 - 2s - loss: 2.4481 - sparse_categorical_accuracy: 0.1724 - val_loss: 2.5160 - val_sparse_categorical_accuracy: 0.1380\n",
      "Epoch 3/8\n",
      "9500/9500 - 2s - loss: 2.4111 - sparse_categorical_accuracy: 0.1754 - val_loss: 2.5395 - val_sparse_categorical_accuracy: 0.1040\n",
      "Epoch 4/8\n",
      "9500/9500 - 2s - loss: 2.4664 - sparse_categorical_accuracy: 0.1813 - val_loss: 2.4335 - val_sparse_categorical_accuracy: 0.1820\n",
      "Epoch 5/8\n",
      "9500/9500 - 2s - loss: 2.4360 - sparse_categorical_accuracy: 0.1847 - val_loss: 2.4108 - val_sparse_categorical_accuracy: 0.2220\n",
      "Epoch 6/8\n",
      "9500/9500 - 2s - loss: 2.4274 - sparse_categorical_accuracy: 0.1844 - val_loss: 2.8920 - val_sparse_categorical_accuracy: 0.1060\n",
      "Epoch 7/8\n",
      "9500/9500 - 2s - loss: 2.3949 - sparse_categorical_accuracy: 0.1954 - val_loss: 2.7175 - val_sparse_categorical_accuracy: 0.1020\n",
      "Epoch 8/8\n",
      "9500/9500 - 2s - loss: 2.4365 - sparse_categorical_accuracy: 0.1926 - val_loss: 2.4916 - val_sparse_categorical_accuracy: 0.1920\n",
      "Starting training on sample 5\n",
      "WARNING:tensorflow:Large dropout rate: 0.506232 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train on 9500 samples, validate on 500 samples\n",
      "Epoch 1/8\n",
      "WARNING:tensorflow:Large dropout rate: 0.506232 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.506232 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "9500/9500 - 4s - loss: 2.0783 - sparse_categorical_accuracy: 0.2886 - val_loss: 1.7731 - val_sparse_categorical_accuracy: 0.3320\n",
      "Epoch 2/8\n",
      "9500/9500 - 2s - loss: 1.5401 - sparse_categorical_accuracy: 0.4358 - val_loss: 1.7828 - val_sparse_categorical_accuracy: 0.3960\n",
      "Epoch 3/8\n",
      "9500/9500 - 2s - loss: 1.4115 - sparse_categorical_accuracy: 0.4836 - val_loss: 1.4860 - val_sparse_categorical_accuracy: 0.4620\n",
      "Epoch 4/8\n",
      "9500/9500 - 2s - loss: 1.3073 - sparse_categorical_accuracy: 0.5191 - val_loss: 1.3344 - val_sparse_categorical_accuracy: 0.5200\n",
      "Epoch 5/8\n",
      "9500/9500 - 2s - loss: 1.2168 - sparse_categorical_accuracy: 0.5636 - val_loss: 1.4179 - val_sparse_categorical_accuracy: 0.4700\n",
      "Epoch 6/8\n",
      "9500/9500 - 2s - loss: 1.1496 - sparse_categorical_accuracy: 0.5873 - val_loss: 1.1535 - val_sparse_categorical_accuracy: 0.5740\n",
      "Epoch 7/8\n",
      "9500/9500 - 2s - loss: 1.0680 - sparse_categorical_accuracy: 0.6165 - val_loss: 1.1340 - val_sparse_categorical_accuracy: 0.6120\n",
      "Epoch 8/8\n",
      "9500/9500 - 2s - loss: 1.0153 - sparse_categorical_accuracy: 0.6398 - val_loss: 1.0931 - val_sparse_categorical_accuracy: 0.6020\n"
     ]
    }
   ],
   "source": [
    "params={'learning_rate':(1e-4,1e-1,2),\n",
    "        'batch_size':(32,256,1),\n",
    "        'nepochs':(8,8,1),\n",
    "        'conv_size1':(32,128,1),\n",
    "        'conv_size2':(32,128,1),\n",
    "        'conv_size3':(32,128,1),\n",
    "        'fc_size':(50,200,1),\n",
    "        'dropout_param':(0,0.8,0),\n",
    "        'l2_reg':(1e-10,1,2)}\n",
    "best_params,best_score=randomSearch(5,params=params,num_training=9500,num_val=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.618\n"
     ]
    }
   ],
   "source": [
    "print(best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on n samples on full dataset and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [02:29<2:11:49, 80.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.640376 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.640376 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [1:59:42<00:00, 71.82s/it] \n"
     ]
    }
   ],
   "source": [
    "n=100\n",
    "params={'learning_rate':(1e-4,1e-1,2),\n",
    "        'batch_size':(32,256,1),\n",
    "        'nepochs':(8,8,1),\n",
    "        'conv_size1':(32,128,1),\n",
    "        'conv_size2':(32,128,1),\n",
    "        'conv_size3':(32,128,1),\n",
    "        'fc_size':(50,200,1),\n",
    "        'dropout_param':(0,0.8,0),\n",
    "        'l2_reg':(1e-10,1,2)}\n",
    "best_params,best_score=randomSearch(n,params=params,keras_verbose=0)\n",
    "save_obj(best_params,'RandOptParam2')\n",
    "save_obj(best_score,'RandScore2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nepochs': 8, 'learning_rate': 0.0007554045569226791, 'batch_size': 42.0, 'conv_size1': 88.0, 'conv_size2': 68.0, 'conv_size3': 125.0, 'fc_size': 185.0, 'dropout_param': 0.3617849015911418, 'l2_reg': 3.937373308580236e-09}\n"
     ]
    }
   ],
   "source": [
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
